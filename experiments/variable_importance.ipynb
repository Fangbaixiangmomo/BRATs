{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Importance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"../src\"))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from BRAT.algorithms import BRATD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generating Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "n, d = 1000, 5\n",
    "X = rng.uniform(0, 1, (n, d))\n",
    "y = np.sin(2*np.pi*X[:,0]) + 0.5*X[:,1] + rng.normal(scale=1, size=n)\n",
    "\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=0\n",
    ")\n",
    "d_check = 2\n",
    "X_train_sub = X_train[:, :d_check]\n",
    "X_hold_sub  = X_hold[:,  :d_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = dict(\n",
    "    n_estimators   = 100,\n",
    "    learning_rate  = 1.0,\n",
    "    max_depth      = 6,\n",
    "    subsample_rate = 0.8,\n",
    "    dropout_rate   = 0.8,\n",
    "    disable_tqdm   = False,\n",
    ")\n",
    "model_full = BRATD(**common)\n",
    "model_full.fit(X_train,    y_train, X_hold,    y_hold)\n",
    "\n",
    "model_sub = BRATD(**common)\n",
    "model_sub.fit(X_train_sub, y_train, X_hold_sub, y_hold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Difference Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full.full_K()\n",
    "model_sub .full_K()\n",
    "\n",
    "m_pts = X_hold.shape[0]\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "R_full = np.zeros((m_pts, n_train))\n",
    "R_sub  = np.zeros((m_pts, n_train))\n",
    "\n",
    "for j, x in tqdm(enumerate(X_hold), desc = \"Sketching R_full, R_sub\", total=m_pts):\n",
    "    rn_full, _ = model_full.sketch_r(x, vector=True)\n",
    "    rn_sub,  _ = model_sub .sketch_r(x[:d_check], vector=True)\n",
    "    R_full[j, :] = rn_full\n",
    "    R_sub [j, :] = rn_sub\n",
    "\n",
    "R_diff = R_full - R_sub  # shape: m*n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Noise Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sigma2 = model_full.est_sigma_hat2(in_bag=False)\n",
    "sub_sigma2  = model_sub .est_sigma_hat2(in_bag=False)\n",
    "sigma2 = (full_sigma2 + sub_sigma2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VCV matrix calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = sigma2 * (R_diff @ R_diff.T)\n",
    "Sigma += 1e-8 * np.eye(m_pts)      # numerical ridge\n",
    "Sigma_inv = np.linalg.inv(Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = model_full.predict(X_hold) - model_sub.predict(X_hold_sub)  # m-vector\n",
    "T = float(delta.T @ Sigma_inv @ delta)\n",
    "p_val = 1 - chi2.cdf(T, df=m_pts)\n",
    "\n",
    "print(\"==============================================\")\n",
    "print(f\"Chi2 test (m = {m_pts} test points)\")\n",
    "print(f\"  Test statistic     T = {T:.3f}\")\n",
    "print(f\"  Degrees of freedom    = {m_pts}\")\n",
    "print(f\"  sigma_hat2               = {sigma2:.4e}\")\n",
    "print(f\"  p-value               = {p_val:.4g}\")\n",
    "print(\"  Decision (alpha=0.05):\", \"REJECT\" if p_val < 0.05 else \"FAIL TO REJECT\")\n",
    "print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type I, II Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(66)\n",
    "def run_test(n, weight_third=0.0, d=5, m_hold_pct=0.1, **common):\n",
    "    \"\"\"\n",
    "    Runs the variable importance test for one dataset of size n.\n",
    "    weight_third: signal weight for the third covariate (null=0, alternative>0).\n",
    "    Returns p-value.\n",
    "    \"\"\"\n",
    "    X = rng.uniform(0, 5, (n, d))\n",
    "    # Generate y with optional signal in X[:,2]\n",
    "    y = (4 * X[:,0]\n",
    "        - X[:,1]**2\n",
    "        + weight_third * (X[:,2])\n",
    "        + rng.normal(scale=0.01, size=n)\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Train/hold split\n",
    "    X_train, X_hold, y_train, y_hold = train_test_split(\n",
    "        X, y, test_size=m_hold_pct, random_state=0\n",
    "    )\n",
    "    d_check = 2\n",
    "    X_train_sub = X_train[:, :d_check]\n",
    "    X_hold_sub  = X_hold[:,  :d_check]\n",
    "    \n",
    "    # Fit full and sub models\n",
    "    model_full = BRATD(**common)\n",
    "    model_full.fit(X_train, y_train, X_hold, y_hold)\n",
    "    model_sub = BRATD(**common)\n",
    "    model_sub.fit(X_train_sub, y_train, X_hold_sub, y_hold)\n",
    "    \n",
    "    # Build R matrices\n",
    "    model_full.full_K()\n",
    "    model_sub.full_K()\n",
    "    m_pts = X_hold.shape[0]\n",
    "    n_train = X_train.shape[0]\n",
    "    \n",
    "    R_full = np.zeros((m_pts, n_train))\n",
    "    R_sub  = np.zeros((m_pts, n_train))\n",
    "    for j, x in enumerate(X_hold):\n",
    "        rn_full, _ = model_full.sketch_r(x, vector=True)\n",
    "        rn_sub,  _ = model_sub.sketch_r(x[:d_check], vector=True)\n",
    "        R_full[j, :] = rn_full\n",
    "        R_sub [j, :] = rn_sub\n",
    "    \n",
    "    R_diff = R_full - R_sub\n",
    "    full_sigma2 = model_full.est_sigma_hat2(in_bag=False)\n",
    "    sigma2 = full_sigma2\n",
    "    \n",
    "    Sigma = sigma2 * (R_diff @ R_diff.T)\n",
    "    Sigma_inv = np.linalg.pinv(Sigma)\n",
    "    \n",
    "    delta = model_full.predict(X_hold) - model_sub.predict(X_hold_sub)\n",
    "    T = float(delta.T @ Sigma_inv @ delta)\n",
    "    p_val = 1 - chi2.cdf(T, df=m_pts)\n",
    "    return R_diff, sigma2, Sigma, Sigma_inv, T, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation settings\n",
    "n_list = [20, 30, 50, 80, 100, 200]\n",
    "train_n_list = [n * 0.9 for n in n_list]\n",
    "\n",
    "reps = 30\n",
    "common_params = dict(\n",
    "    n_estimators   = 100,\n",
    "    learning_rate  = 1.0,\n",
    "    max_depth      = 8,\n",
    "    subsample_rate = 1.0,\n",
    "    dropout_rate   = 0.95,\n",
    "    disable_tqdm   = True,\n",
    ")\n",
    "\n",
    "type1_errors = []\n",
    "type2_errors = []\n",
    "\n",
    "for n in n_list:\n",
    "    results_null = [run_test(n, weight_third=0.0, **common_params) for _ in tqdm(range(reps), desc=f\"Type I at n={n}\")]\n",
    "    results_alt  = [run_test(n, weight_third=5.0, **common_params) for _ in tqdm(range(reps), desc=f\"Type II at n={n}\")]\n",
    "    R_diffs_null, sigma2s_null, Sigmas_null, Sigmas_inv_null, T_nulls, pvals_nulls = zip(*results_null)\n",
    "    R_diffs_alt, sigma2s_alt, Sigmas_alt, Sigmas_inv_alt, T_alts, pvals_alts = zip(*results_alt)\n",
    "    \n",
    "    # summaries under null\n",
    "    rdn = np.array(R_diffs_null)         # shape (reps, m_hold, n_train)\n",
    "    s2n = np.array(sigma2s_null)         # shape (reps,)\n",
    "    Tin = np.array(T_nulls)              # shape (reps,)\n",
    "\n",
    "    print(f\"R_diff under null:       {rdn.mean():.3f} ± {rdn.std():.3f}\")\n",
    "    print(f\"sigma2 under null:       {s2n.mean():.3f} ± {s2n.std():.3f}\")\n",
    "    print(f\"T-statistic under null:  {Tin.mean():.3f} ± {Tin.std():.3f}\")\n",
    "\n",
    "    # summaries under alt\n",
    "    rda = np.array(R_diffs_alt)\n",
    "    s2a = np.array(sigma2s_alt)\n",
    "    Tia = np.array(T_alts)\n",
    "\n",
    "    print(f\"R_diff under alt:        {rda.mean():.3f} ± {rda.std():.3f}\")\n",
    "    print(f\"sigma2 under alt:        {s2a.mean():.3f} ± {s2a.std():.3f}\")\n",
    "    print(f\"T-statistic under alt:   {Tia.mean():.3f} ± {Tia.std():.3f}\")\n",
    "\n",
    "    # Type I error (false positive rate under null)\n",
    "    type1_errors.append(np.mean(np.array(pvals_nulls) < 0.05))\n",
    "    # Type II error (false negative rate under alternative)\n",
    "    type2_errors.append(np.mean(np.array(pvals_alts) >= 0.05))\n",
    "    print(f\"Type I error at n={n}: {type1_errors[-1]:.3f}\")\n",
    "    print('Test statistic under null:', T_nulls)\n",
    "    print(f\"Type II error at n={n}: {type2_errors[-1]:.3f}\")\n",
    "    print('Test statistic under alternative:', T_alts)\n",
    "\n",
    "out_dir = './variable_importance/'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'n':            train_n_list,\n",
    "    'type_I_error': type1_errors,\n",
    "    'type_II_error': type2_errors\n",
    "})\n",
    "\n",
    "results.to_csv(os.path.join(out_dir, 'size_and_power.csv'), index=False)\n",
    "print(f\"Saved summary to {os.path.join(out_dir, 'size_and_power.csv')}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.plot(train_n_list, type1_errors, marker='o', label='Type I Error')\n",
    "plt.plot(train_n_list, type2_errors, marker='o', label='Type II Error')\n",
    "plt.xlabel('Training sample size (n)')\n",
    "plt.ylabel('Error rate')\n",
    "plt.title('Type I and Type II Error Curves')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
