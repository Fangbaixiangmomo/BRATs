{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"../src\"))\n",
    "from BRAT.algorithms import BRATD, BRATP\n",
    "from BRAT.utils import load_and_clean_uci_data, train_all_models, plot_mean_std_trajectories\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the MSE horserace we presented in the paper. We segement this notebook into 9 sections, with each section containing the experiments for each individual dataset. The datasets we used are:\n",
    "1. [Air Quality](https://archive.ics.uci.edu/dataset/360/air+quality)\n",
    "2. [Abalone](https://archive.ics.uci.edu/dataset/1/abalone)\n",
    "3. [Obesity Level](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition)\n",
    "4. [Infared Thermography Temperature](https://archive.ics.uci.edu/dataset/925/infrared+thermography+temperature+dataset)\n",
    "5. [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality)\n",
    "6. [Communities and Crimes](https://archive.ics.uci.edu/dataset/183/communities+and+crime)\n",
    "7. [AIDS Clinical Trials Group Study 175](https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175)\n",
    "8. [Automobile](https://archive.ics.uci.edu/dataset/10/automobile)\n",
    "9. [Student Performance](https://archive.ics.uci.edu/dataset/320/student+performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset, the first cell creates a optuna study of the hyperparameters according the following configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for the minute\n",
    "X_train, y_train, X_test, y_test = None, None, None, None\n",
    "def objective_gbt(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "    }\n",
    "    model = GradientBoostingRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    }\n",
    "    model = XGBRegressor(**params, use_label_encoder=False, eval_metric='rmse')\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 16),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "    }\n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "    }\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def objective_elasticnet(trial):\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 0.1, 10.0),\n",
    "        'l1_ratio': trial.suggest_float('l1_ratio', 0.1, 1.0),\n",
    "    }\n",
    "    model = ElasticNet(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def objective_bratd(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 1.0),\n",
    "        'subsample_rate': trial.suggest_float('subsample_rate', 0.5, 1.0),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.99),\n",
    "    }\n",
    "    model = BRATD(**params, disable_tqdm=True)\n",
    "    model.fit(X_train, y_train, X_test, y_test)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def objective_boulevard(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 1.0),\n",
    "        'subsample_rate': trial.suggest_float('subsample_rate', 0.5, 1.0),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.0, 0.0),\n",
    "    }\n",
    "    model = BRATD(**params, disable_tqdm=True)\n",
    "    model.fit(X_train, y_train, X_test, y_test)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def objective_bratp(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 1.0),\n",
    "        'subsample_rate': trial.suggest_float('subsample_rate', 0.5, 1.0),\n",
    "        'n_trees_per_group': trial.suggest_int('n_trees_per_group', 2, 30),\n",
    "    }\n",
    "    model = BRATP(**params, disable_tqdm=True)\n",
    "    model.fit(X_train, y_train, X_test, y_test)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the suggestions to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = Path(\"optuna_suggestions\")\n",
    "storage_dir.mkdir(parents=True, exist_ok=True)\n",
    "mse_dir = Path(\"mse_trajectory/data/\")\n",
    "mse_dir.mkdir(parents=True, exist_ok=True)\n",
    "plot_dir = Path(\"mse_trajectory/plots/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For detailed manual to reproduce the results, see Air Quality for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will optimize the hyperparameters of each model and save them to the storage url `../experiments/optuna_suggestions/`. After running it, you should see a corresponding `db` file and a `csv` file. The `db` file stores the trajectory of the optimization executed by Optuna. You can open it using Optuna Dashboard, available in VSCode extension. The `csv` file stores the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 360\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id, target_column='C6H6(GT)')\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'air_quality.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    # Try to load an existing study; if it doesn't exist, create a new one\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    # Skip optimization if the study already has trials\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply fill in the tuned hyperparameters in the next cell we obtain the results in the paper. You can see the stored trajectory at `../experiments/mse_trajectory/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 360\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    target_column='C6H6(GT)',      \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.029,\n",
    "        'max_depth': 5\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.07,\n",
    "        'max_depth': 11,\n",
    "        'subsample': 0.55\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 6,\n",
    "        'num_leaves': 21\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 8\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 0.13,\n",
    "        'l1_ratio': 1.0\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 13,\n",
    "        'min_samples_split': 13,\n",
    "        'learning_rate': 0.94,\n",
    "        'subsample_rate': 0.98,\n",
    "        'dropout_rate': 0.11\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 13,\n",
    "        'min_samples_split': 8,\n",
    "        'learning_rate': 0.73,\n",
    "        'subsample_rate': 0.99,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 20,\n",
    "        'learning_rate': 0.93,\n",
    "        'subsample_rate': 0.79,\n",
    "        'n_trees_per_group': 6\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "# Flatten mse_runs into a DataFrame\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Sort by Model and Run_ID\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Plot and save the aggregated results\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Air Quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 1\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id)\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'abalone.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 1\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 3\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 4,\n",
    "        'subsample': 0.63\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 9,\n",
    "        'num_leaves': 37\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 11\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 0.13,\n",
    "        'l1_ratio': 0.38\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 43,\n",
    "        'learning_rate': 0.55,\n",
    "        'subsample_rate': 0.51,\n",
    "        'dropout_rate': 0.48\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 42,\n",
    "        'learning_rate': 0.57,\n",
    "        'subsample_rate': 0.51,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 5,\n",
    "        'learning_rate': 0.27,\n",
    "        'subsample_rate': 0.63,\n",
    "        'n_trees_per_group': 16\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "# Flatten mse_runs into a DataFrame\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Sort by Model and Run_ID\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Plot and save the aggregated results\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Abalone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 544\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id)\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'obesity.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 544\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.19,\n",
    "        'max_depth': 7\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.09,\n",
    "        'max_depth': 7,\n",
    "        'subsample': 0.81\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.08,\n",
    "        'max_depth': 16,\n",
    "        'num_leaves': 25\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 0.21,\n",
    "        'l1_ratio': 0.12\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 3,\n",
    "        'learning_rate': 0.25,\n",
    "        'subsample_rate': 0.65,\n",
    "        'dropout_rate': 0.81\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 3,\n",
    "        'learning_rate': 0.54,\n",
    "        'subsample_rate': 0.79,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 11,\n",
    "        'min_samples_split': 4,\n",
    "        'learning_rate': 0.36,\n",
    "        'subsample_rate': 0.56,\n",
    "        'n_trees_per_group': 4\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Obesity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infared Thermography Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 925\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id, target_column='aveOralF')\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'temperature.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 925\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    target_column = 'aveOralF',\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "# 2. Which models to include\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 5\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.70\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.18,\n",
    "        'max_depth': 1,\n",
    "        'num_leaves': 24\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 20\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 3.81,\n",
    "        'l1_ratio': 0.96\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 4,\n",
    "        'learning_rate': 0.76,\n",
    "        'subsample_rate': 0.51,\n",
    "        'dropout_rate': 0.23\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 4,\n",
    "        'learning_rate': 0.65,\n",
    "        'subsample_rate': 0.54,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 9,\n",
    "        'learning_rate': 0.98,\n",
    "        'subsample_rate': 0.64,\n",
    "        'n_trees_per_group': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "# Flatten mse_runs into a DataFrame\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Sort by Model and Run_ID\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Plot and save the aggregated results\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Infrared Thermography Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 186\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id)\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'wine_quality.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 186\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.17,\n",
    "        'max_depth': 7\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.04,\n",
    "        'max_depth': 9,\n",
    "        'subsample': 0.60\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1,\n",
    "        'num_leaves': 47\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 20\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 3.81,\n",
    "        'l1_ratio': 0.96\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 8,\n",
    "        'learning_rate': 0.71,\n",
    "        'subsample_rate': 0.75,\n",
    "        'dropout_rate': 0.41\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 15,\n",
    "        'min_samples_split': 5,\n",
    "        'learning_rate': 0.97,\n",
    "        'subsample_rate': 0.59,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 13,\n",
    "        'learning_rate': 0.82,\n",
    "        'subsample_rate': 0.67,\n",
    "        'n_trees_per_group': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "# Flatten mse_runs into a DataFrame\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Sort by Model and Run_ID\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Plot and save the aggregated results\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Wine Quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communities and Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 183\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id)\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'community_crime.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 183\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "# 2. Which models to include\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.15,\n",
    "        'max_depth': 7\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.07,\n",
    "        'max_depth': 4,\n",
    "        'subsample': 0.87\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.015,\n",
    "        'max_depth': 6,\n",
    "        'num_leaves': 38\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 18\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 3.81,\n",
    "        'l1_ratio': 0.96\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 8,\n",
    "        'learning_rate': 0.71,\n",
    "        'subsample_rate': 0.75,\n",
    "        'dropout_rate': 0.41\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 15,\n",
    "        'min_samples_split': 5,\n",
    "        'learning_rate': 0.97,\n",
    "        'subsample_rate': 0.59,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 4,\n",
    "        'min_samples_split': 5,\n",
    "        'learning_rate': 0.35,\n",
    "        'subsample_rate': 0.51,\n",
    "        'n_trees_per_group': 11\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "# Flatten mse_runs into a DataFrame\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Sort by Model and Run_ID\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Plot and save the aggregated results\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Communities and Crime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDS Clinical Trials Group Study 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 890\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id)\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'aids.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 890\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.75\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 9,\n",
    "        'num_leaves': 37\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 5\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 3.81,\n",
    "        'l1_ratio': 0.96\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 4,\n",
    "        'min_samples_split': 12,\n",
    "        'learning_rate': 0.85,\n",
    "        'subsample_rate': 0.53,\n",
    "        'dropout_rate': 0.34\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 4,\n",
    "        'min_samples_split': 27,\n",
    "        'learning_rate': 0.91,\n",
    "        'subsample_rate': 0.73,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 4,\n",
    "        'min_samples_split': 46,\n",
    "        'learning_rate': 0.3,\n",
    "        'subsample_rate': 0.53,\n",
    "        'n_trees_per_group': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"AIDS Clinical Trials Group Study 175\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 10\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id)\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'automobile.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 10\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.2,\n",
    "        'max_depth': 3\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.22,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.98\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.23,\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 37\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 14\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 0.36,\n",
    "        'l1_ratio': 0.14\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 6,\n",
    "        'min_samples_split': 23,\n",
    "        'learning_rate': 0.94,\n",
    "        'subsample_rate': 0.94,\n",
    "        'dropout_rate': 0.21\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 11,\n",
    "        'min_samples_split': 9,\n",
    "        'learning_rate': 0.14,\n",
    "        'subsample_rate': 0.98,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 30,\n",
    "        'learning_rate': 0.57,\n",
    "        'subsample_rate': 0.73,\n",
    "        'n_trees_per_group': 16\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Automobile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 320\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(uci_id, target_column='G3')\n",
    "\n",
    "models = {\n",
    "    'GBT': objective_gbt,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'LightGBM': objective_lgbm,\n",
    "    'RF': objective_rf,\n",
    "    'ElasticNet': objective_elasticnet,\n",
    "    'BRATD':objective_bratd,\n",
    "    'Boulevard': objective_boulevard,\n",
    "    'BRATP': objective_bratp\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "storage_url = f\"sqlite:///{storage_dir / 'student.db'}\"\n",
    "\n",
    "for model_name, objective in models.items():\n",
    "    sampler = TPESampler(\n",
    "        n_startup_trials=5,\n",
    "        n_ei_candidates=50,\n",
    "        consider_prior=True,\n",
    "        multivariate=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        n_min_trials=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        study = optuna.load_study(study_name=model_name, storage=storage_url)\n",
    "        print(f\"Loaded existing study for {model_name}.\")\n",
    "    except KeyError:\n",
    "        study = optuna.create_study(\n",
    "            study_name=model_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize',\n",
    "            sampler=sampler,\n",
    "            pruner=pruner\n",
    "        )\n",
    "        print(f\"Created new study for {model_name}.\")\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "        print(f\"Running optimization for {model_name}...\")\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        best_params[model_name] = study.best_params\n",
    "        print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "        print(f\"Best MSE for {model_name}: {study.best_value}\")\n",
    "    else:\n",
    "        print(f\"Study for {model_name} already has trials. Skipping optimization.\")\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "output_dir = storage_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f'{uci_id}_manual_tuning.csv')\n",
    "\n",
    "best_params_df = pd.DataFrame.from_dict(best_params, orient='index')\n",
    "best_params_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_id = 320\n",
    "X_train, X_test, y_train, y_test = load_and_clean_uci_data(\n",
    "    dataset_id=uci_id,\n",
    "    target_column = 'G3',                 \n",
    "    test_size=0.2,                  \n",
    "    random_state=42,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "models = [\n",
    "    'GBT', 'XGBoost', 'LightGBM',\n",
    "    'RF', 'ElasticNet',\n",
    "    'BRATD', 'Boulevard', 'BRATP'\n",
    "]\n",
    "\n",
    "manual_configs = {\n",
    "    'GBT': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.57\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.03,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 38\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 11\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': 0.49,\n",
    "        'l1_ratio': 0.14\n",
    "    },\n",
    "    'BRATD': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 39,\n",
    "        'learning_rate': 0.93,\n",
    "        'subsample_rate': 0.84,\n",
    "        'dropout_rate': 0.12\n",
    "    },\n",
    "    'Boulevard': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 9,\n",
    "        'min_samples_split': 32,\n",
    "        'learning_rate': 0.87,\n",
    "        'subsample_rate': 0.52,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'BRATP': {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 48,\n",
    "        'learning_rate': 0.98,\n",
    "        'subsample_rate': 0.60,\n",
    "        'n_trees_per_group': 13\n",
    "    }\n",
    "}\n",
    "\n",
    "mse_runs = []\n",
    "\n",
    "for i in range(5):\n",
    "    mse_dict, best_params = train_all_models(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        epoch=epoch,\n",
    "        tune=False,\n",
    "        models=models,\n",
    "        manual_configs=manual_configs,\n",
    "        run_idx=i\n",
    "    )\n",
    "    mse_runs.append(mse_dict)\n",
    "\n",
    "flattened_data = []\n",
    "for run_id, mse_dict in enumerate(mse_runs, start=1):\n",
    "    for model_name, mse_values in mse_dict.items():\n",
    "        for epoch_idx, mse in enumerate(mse_values, start=1):\n",
    "            flattened_data.append({\n",
    "                'Model': model_name,\n",
    "                'Run_ID': run_id,\n",
    "                'Epoch': epoch_idx,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "mse_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "mse_df = mse_df.sort_values(by=['Model', 'Run_ID', 'Epoch']).reset_index(drop=True)\n",
    "output_path = os.path.join(mse_dir, f'{uci_id}.csv')\n",
    "mse_df.to_csv(output_path, index=False)\n",
    "\n",
    "plot_mean_std_trajectories(mse_runs, epoch, dataset_id=uci_id, plot_dir=plot_dir, title=\"Student Performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
